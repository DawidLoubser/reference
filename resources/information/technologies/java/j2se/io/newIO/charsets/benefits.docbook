<?xml version="1.0" encoding="UTF-8"?><?oxygen RNGSchema="http://www.oasis-open.org/docbook/xml/5.0/rng/docbookxi.rng" type="xml"?>
<!-- @author Dawid Loubser --><section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="resources.information.technologies.java.j2se.io.newIO.charsets.benefits">
    
    <title>Why the need for Character Sets?</title>
    <para>
        The many different character sets in existence use different encoding algorithms
        to translate characters into bytes. In the olden days, <literal>ASCII</literal>
        could easily be accommodated with a simple character-to-byte mapping, because 255
        different characters was more than enough to store all the required english symbols.
    </para>
    <para>
        When one considers Arabic, Hebrew, Japanese and Chinese, it is apparent that <emphasis>thousands</emphasis> of
        different characters need to be catered for, and hence, a single character can now span
        one, two, or even three bytes. When text data is read using byte buffers, a pluggable decoding algorithm
        is required to correctly interpret the characters. Furthermore, when text is written, a choice should be made
        as to the encoding.
    </para>
    <para>
        The following simplistic example shows how to decode and display characters using NIO:
        <programlisting language="Java"><![CDATA[
]]><xi:include href="src/TextDisplay.java" parse="text"/><![CDATA[
        ]]></programlisting>
        <note>
            <para>
                When reading or writing text data, the Stream-based <literal>Readers</literal> and <literal>Writers</literal>
                (in the <literal>java.io</literal> package) are usually more suited in terms of implementation simplicity. They use encoders and decoders under the hood.
            </para>
        </note>
    </para>
    
</section>